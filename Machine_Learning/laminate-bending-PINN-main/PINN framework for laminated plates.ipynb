{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabb8104",
   "metadata": {},
   "source": [
    "## PINN framework for laminated plates\n",
    "This framework predicts the bending behavior of laminated plates based on Classical Laminate Plate Theory (CLPT). Taking a simply supported (0/90) plate under uniform distributed load (UDL) as an example, other cases can be predicted by modifying the parameters in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0bb3d",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CUDA cache and check for available device (GPU or CPU)\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} (CUDA available: {torch.cuda.is_available()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c48f62",
   "metadata": {},
   "source": [
    "## Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28656acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[20, 20, 5], activation='tanh'):\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_size[0]))\n",
    "        if activation == 'relu':\n",
    "            layers.append(nn.ReLU())\n",
    "        elif activation == 'sigmoid':\n",
    "            layers.append(nn.Sigmoid())\n",
    "        elif activation == 'tanh':\n",
    "            layers.append(nn.Tanh())\n",
    "        else:\n",
    "            layers.append(nn.Softplus())    \n",
    "            \n",
    "        for i in range(len(hidden_size) - 1):\n",
    "            layers.append(nn.Linear(hidden_size[i], hidden_size[i+1]))\n",
    "            if activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == 'sigmoid':\n",
    "                layers.append(nn.Sigmoid())\n",
    "            elif activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            else:\n",
    "                layers.append(nn.Softplus())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_size[-1], output_size))\n",
    "    \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto differential\n",
    "def auto_grad(u, x, order=1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(u, x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "    return auto_grad(auto_grad(u, x), x, order - 1)\n",
    "\n",
    "# Xavier initialization\n",
    "def xavier_init(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)  # Xavier initialization for weights\n",
    "        nn.init.zeros_(layer.bias)  # Initialize biases to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce055228",
   "metadata": {},
   "source": [
    "## CLPT stiffness matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the transformed matrix\n",
    "def transformed_matrix(phi,opt):\n",
    "\n",
    "    anpha=np.deg2rad(phi)\n",
    "    m=math.cos(anpha)\n",
    "    n=math.sin(anpha)\n",
    "    if abs(m) < 2.2204e-10:\n",
    "        m=0\n",
    "    if abs(n) < 2.2204e-10:\n",
    "        n=0    \n",
    "  \n",
    "    if opt==1:\n",
    "        T = np.array([[m**2, n**2, 2*m*n ],\n",
    "                   [n**2, m**2, -2*m*n ],\n",
    "                   [-m*n, m*n, m**2-n**2]])\n",
    "    else:\n",
    "        T = np.array([[m**2, n**2, m*n ],\n",
    "                   [n**2, m**2, -m*n ],\n",
    "                   [-2*m*n, 2*m*n, m**2-n**2]])\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define geometric parameters\n",
    "a = 5 \n",
    "b = 5 \n",
    "h = 1 # Total thickness of the laminate\n",
    "n_layer = 2 # Number of layers\n",
    "t = h/n_layer # Thickness of each layer\n",
    "phi = [0,90] # lay-ups\n",
    "q0 = 1e-3 \n",
    "# SDL: q0 * torch.sin(3.1415/2*(x[:,0]+1)).view(-1,1)* torch.sin(3.1415/2*(x[:,1]+1)).view(-1,1)\n",
    "\n",
    "# Define material parameters\n",
    "E1 = 25\n",
    "E2 = E1/25\n",
    "G12 = 0.5*E2\n",
    "mu12 = 0.25\n",
    "mu21 = mu12*E2/E1\n",
    "\n",
    "# Stiffness matrix for an orthotropic material\n",
    "Q11 = E1/(1 - mu12*mu21)\n",
    "Q12 = mu12*E2/(1 - mu12*mu21)\n",
    "Q22 = E2/(1 - mu12*mu21)\n",
    "Q66 = G12    \n",
    "Q = np.array([[Q11, Q12 , 0],[Q12 , Q22, 0],[0, 0, Q66]])\n",
    "\n",
    "# Transform stiffness matrix for each layer\n",
    "Q_bar =[]\n",
    "for i in range(n_layer):\n",
    "        T2=transformed_matrix(phi[i],2)\n",
    "        Q2=T2.T@Q@T2\n",
    "        Q_bar.append(Q2)\n",
    "        \n",
    "# Calculate z-coordinates for each layer       \n",
    "z1 = []\n",
    "for i in range(n_layer):\n",
    "    zi=((i)-n_layer/2)*t\n",
    "    z1.append(zi)\n",
    "z1 = np.array(z1)\n",
    "\n",
    "z2 = []\n",
    "for i in range(n_layer):\n",
    "    zi=((i+1)-n_layer/2)*t\n",
    "    z2.append(zi)\n",
    "z2 = np.array(z2)\n",
    "\n",
    "# Compute A, B, D matrices\n",
    "A = np.zeros(shape=(3,3))\n",
    "B = np.zeros(shape=(3,3))\n",
    "D = np.zeros(shape=(3,3))\n",
    "for i in range(n_layer):\n",
    "    A = A + Q_bar[i] * (z2[i] - z1[i])\n",
    "    B = B + Q_bar[i] * (z2[i]**2 - z1[i]**2)/2\n",
    "    D = D + Q_bar[i] * (z2[i]**3 - z1[i]**3)/3\n",
    "print(\"A matrix:\\n\", A)\n",
    "print(\"B matrix:\\n\", B)\n",
    "print(\"D matrix:\\n\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf233e3f",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling point\n",
    "def train_data(Nx, Ny, Nf):\n",
    "    \n",
    "    xu = np.linspace(-1, 1, Nx).reshape([Nx, 1])\n",
    "    yu = np.linspace(-1, 1, Ny).reshape([Ny, 1]) \n",
    "    X, Y = np.meshgrid(xu, yu)\n",
    "    Xf1 = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    Xf1 = torch.tensor(Xf1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    Xf2 = np.random.rand(Nf,2)*2-1\n",
    "    Xf2 = torch.tensor(Xf2, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    return Xf1, Xf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "Nxb= 100\n",
    "Nyb = 100\n",
    "Nf1 = 10000\n",
    "\n",
    "Xf1, Xf2 = train_data(Nxb, Nyb, Nf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5dd83",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d927172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy_loss(x, Net_w, func_w, Net_u, func_u, Net_v, func_v):\n",
    "    \n",
    "    q = q0\n",
    "    # SDL: q = q0 * torch.sin(3.1415/2*(x[:,0]+1)).view(-1,1)* torch.sin(3.1415/2*(x[:,1]+1)).view(-1,1)    \n",
    "    u = Net_u(x)*(func_u(x).view(-1,1))\n",
    "    du_x = auto_grad(u, x, 1)[:,0].view(-1,1)\n",
    "    du_y = auto_grad(u, x, 1)[:,1].view(-1,1)\n",
    "    v = Net_v(x)*(func_v(x).view(-1,1))\n",
    "    dv_x = auto_grad(v, x, 1)[:,0].view(-1,1)\n",
    "    dv_y = auto_grad(v, x, 1)[:,1].view(-1,1)\n",
    "    w = Net_w(x)*(func_w(x).view(-1,1))\n",
    "    dw_x = auto_grad(w, x, 1)[:,0].view(-1,1)\n",
    "    dw_y = auto_grad(w, x, 1)[:,1].view(-1,1)\n",
    "    dw_xx = auto_grad(dw_x, x, 1)[:,0].view(-1,1)\n",
    "    dw_yy = auto_grad(dw_y, x, 1)[:,1].view(-1,1)\n",
    "    dw_xy = auto_grad(dw_x, x, 1)[:,1].view(-1,1)\n",
    "    \n",
    "    w = w*h\n",
    "    dw_x, dw_y, du_y, dv_x = dw_x*h/a, dw_y*h/b, du_y*a/b, dv_x*b/a\n",
    "    dw_xx, dw_yy, dw_xy = dw_xx*h/a**2, dw_yy*h/b**2, dw_xy*h/a/b\n",
    "    \n",
    "    eps_xx = du_x + 0.5*dw_x**2\n",
    "    eps_yy = dv_y + 0.5*dw_y**2\n",
    "    eps_xy = 0.5*(du_y + dv_x) + 0.5*dw_y*dw_x   \n",
    "        \n",
    "    k_xx = -dw_xx\n",
    "    k_yy = -dw_yy\n",
    "    k_xy = -dw_xy\n",
    "    \n",
    "    N_xx = A[0,0]*eps_xx + A[0,1]*eps_yy + A[0,2]*2*eps_xy  + B[0,0]*k_xx + B[0,1]*k_yy + B[0,2]*2*k_xy \n",
    "    N_yy = A[1,0]*eps_xx + A[1,1]*eps_yy + A[1,2]*2*eps_xy  + B[1,0]*k_xx + B[1,1]*k_yy + B[1,2]*2*k_xy \n",
    "    N_xy = A[2,0]*eps_xx + A[2,1]*eps_yy + A[2,2]*2*eps_xy  + B[2,0]*k_xx + B[2,1]*k_yy + B[2,2]*2*k_xy \n",
    "   \n",
    "    M_xx = B[0,0]*eps_xx + B[0,1]*eps_yy + B[0,2]*2*eps_xy  + D[0,0]*k_xx + D[0,1]*k_yy + D[0,2]*2*k_xy\n",
    "    M_yy = B[1,0]*eps_xx + B[1,1]*eps_yy + B[1,2]*2*eps_xy  + D[1,0]*k_xx + D[1,1]*k_yy + D[1,2]*2*k_xy\n",
    "    M_xy = B[2,0]*eps_xx + B[2,1]*eps_yy + B[2,2]*2*eps_xy  + D[2,0]*k_xx + D[2,1]*k_yy + D[2,2]*2*k_xy\n",
    "    \n",
    "    U_m = 0.5*(eps_xx*N_xx + eps_yy*N_yy + 2*eps_xy*N_xy)\n",
    "    U_b = 0.5*(k_xx*M_xx + k_yy*M_yy + 2*k_xy*M_xy)\n",
    "    U_e = q*w \n",
    "    \n",
    "    return torch.mean(U_m), torch.mean(U_b), torch.mean(U_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc15115",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc39ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent nn for three directions\n",
    "Net_w = NeuralNetwork(input_size=2, output_size=1, hidden_size=[5, 5, 5, 5, 5], activation='tanh').to(device)\n",
    "Net_u = NeuralNetwork(input_size=2, output_size=1, hidden_size=[5, 5, 5, 5, 5], activation='tanh').to(device)\n",
    "Net_v = NeuralNetwork(input_size=2, output_size=1, hidden_size=[5, 5, 5, 5, 5], activation='tanh').to(device)\n",
    "Net_w.apply(xavier_init)\n",
    "Net_u.apply(xavier_init)\n",
    "Net_v.apply(xavier_init)\n",
    "\n",
    "# Hard constrains for essential BCs (SSSS)\n",
    "func_w = lambda x: ((x[:,0]+1)*(x[:,0]-1)*(x[:,1]+1)*(x[:,1]-1))\n",
    "func_u = lambda x: (x[:,1]+1)*(x[:,1]-1)\n",
    "func_v = lambda x: (x[:,0]+1)*(x[:,0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimizer\n",
    "params = list(Net_w.parameters()) + list(Net_u.parameters()) + list(Net_v.parameters())\n",
    "optimizer_Adam = torch.optim.Adam(params, lr=0.001)\n",
    "optimizer_LBFGS = torch.optim.LBFGS(params, lr=0.001, max_iter=50000, max_eval=50000, history_size=50,\n",
    "                                   tolerance_grad=1e-5, tolerance_change=1.0 * np.finfo(float).eps, \n",
    "                                   line_search_fn=\"strong_wolfe\")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_Adam, step_size=1000, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da0bf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 10000\n",
    "initial_epochs = 100\n",
    "td = trange(epochs, dynamic_ncols=True, ncols=50)\n",
    "training_loss_hist = []\n",
    "W_pred_hist = []\n",
    "Net_u.train().to(device)\n",
    "Net_v.train().to(device)\n",
    "Net_w.train().to(device)\n",
    "\n",
    "for epoch in td:\n",
    "    if epoch < initial_epochs:\n",
    "        Xf1, _ = train_data(Nxb, Nyb, Nf1)\n",
    "        Xf = Xf1.to(device)\n",
    "    else:\n",
    "        _, Xf2 = train_data(Nxb, Nyb, Nf1)\n",
    "        Xf = Xf2.to(device)\n",
    "        \n",
    "    U_m, U_b, U_e = Energy_loss(Xf, Net_w, func_w, Net_u, func_u, Net_v, func_v)\n",
    "    loss = U_m + U_b - U_e\n",
    "    loss.backward()\n",
    "    optimizer_Adam.step()\n",
    "    optimizer_Adam.zero_grad()\n",
    "    training_loss_hist.append(loss.item())  \n",
    "    #scheduler.step()\n",
    "    if (epoch+1) % 1 ==0: \n",
    "        with torch.no_grad():\n",
    "            W_pred = Net_w(Xf1.to(device))*func_w(Xf1.to(device)).view(-1,1)*100*(h)**3*E2/q0/(2*a)**4\n",
    "            W_pred = W_pred.cpu()\n",
    "            W_pred_hist.append(max(W_pred))\n",
    "\n",
    "    td.set_description(\n",
    "        f\" Total:{loss:.2e}, Um:{U_m:.2e}, Ub:{U_b:.2e}, Ue:{U_e:.4e}, Wmax:{max(W_pred).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867142fa",
   "metadata": {},
   "source": [
    "## Deformation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b87882",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_w.eval().cpu()\n",
    "Net_u.eval().cpu()\n",
    "Net_v.eval().cpu()\n",
    "W = Net_w(Xf1)*(func_w(Xf1).view(-1,1))\n",
    "W_pred = W.detach().numpy().reshape(-1,1)*h\n",
    "W_bar = W_pred*100*(h)**3*E2/q0/(2*a)**4\n",
    "X = Xf1[:,0].detach().numpy().reshape(-1,1)*a\n",
    "Y = Xf1[:,1].detach().numpy().reshape(-1,1)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig, ax = plt.subplots(figsize=(5.8, 4.8)) \n",
    "surf = ax.scatter(X, Y, c=W_bar,cmap=cm.jet)\n",
    "cb = fig.colorbar(surf, ax=ax, orientation='vertical')\n",
    "cb.ax.tick_params(labelsize=16)\n",
    "vmin = W_bar.min().item()\n",
    "vmax = W_bar.max().item()\n",
    "num_ticks = 6\n",
    "ticks = np.linspace(vmin, vmax, num_ticks)\n",
    "cb.set_ticks(ticks)\n",
    "\n",
    "ax.axis('equal')  \n",
    "ax.set_xlabel('X Position (mm)', fontsize=18)\n",
    "ax.set_ylabel('Y Position (mm)', fontsize=18)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_title(r'$\\overline{w}_{0}$ on mid-plane', fontsize=18)\n",
    "ax.set_xlim([X.min(), X.max()])\n",
    "ax.set_ylim([Y.max(), Y.min()])\n",
    "xticks = [-5, -2.5, 0, 2.5, 5] \n",
    "xlabels = ['-a', '-a/2', '0', 'a/2', 'a']\n",
    "yticks = [-5, -2.5, 0, 2.5, 5]\n",
    "ylabels = ['-b', '-b/2', '0', 'b/2', 'b'] \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels, fontsize=16)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels, fontsize=16)\n",
    "ax.set_xlabel('X Position', fontsize=18)\n",
    "ax.set_ylabel('Y Position', fontsize=18)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb948da3",
   "metadata": {},
   "source": [
    "## Stress comparison with FEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEM_data = pd.read_csv('FEM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = FEM_data.iloc[:,0:2].to_numpy()\n",
    "coord_nor = coord/500\n",
    "X = coord_nor[:, 0]\n",
    "Y = coord_nor[:, 1]\n",
    "sigma = FEM_data.iloc[:,3:6].to_numpy()\n",
    "sigmaxx = sigma[:, 0].reshape(-1, 1)\n",
    "sigmayy = sigma[:, 1].reshape(-1, 1)\n",
    "sigmaxy = sigma[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "xticks = [-1, -0.5, 0, 0.5, 1] \n",
    "xlabels = ['-a', '-a/2', '0', 'a/2', 'a']\n",
    "yticks = [-1, -0.5, 0, 0.5, 1]\n",
    "ylabels = ['-b', '-b/2', '0', 'b/2', 'b'] \n",
    "surf1 = axes[0].scatter(X, Y, c=sigmaxx, cmap=cm.jet)\n",
    "cb1 = fig.colorbar(surf1, ax=axes[0], orientation='vertical', shrink=0.8)\n",
    "cb1.ax.tick_params(labelsize=16)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[0].set_ylabel('Y Position (mm)', fontsize=18)\n",
    "axes[0].set_title(r'$\\overline{\\sigma}_{xx}$ Distribution', fontsize=18)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[0].set_xlim([X.min(), X.max()])\n",
    "axes[0].set_ylim([Y.max(), Y.min()])\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf2 = axes[1].scatter(X, Y, c=sigmayy, vmin=0, cmap=cm.jet)\n",
    "cb2 = fig.colorbar(surf2, ax=axes[1], orientation='vertical', shrink=0.8)\n",
    "cb2.ax.tick_params(labelsize=16)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[1].set_title(r'$\\overline{\\sigma}_{yy}$ Distribution', fontsize=18)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[1].set_xlim([X.min(), X.max()])\n",
    "axes[1].set_ylim([Y.max(), Y.min()])\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf3 = axes[2].scatter(X, Y, c=-sigmaxy, cmap=cm.jet)\n",
    "cb3 = fig.colorbar(surf3, ax=axes[2], orientation='vertical', shrink=0.8)\n",
    "cb3.ax.tick_params(labelsize=16)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[2].set_title(r'$\\overline{\\sigma}_{xy}$ Distribution', fontsize=18)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[2].set_xlim([X.min(), X.max()])\n",
    "axes[2].set_ylim([Y.max(), Y.min()])\n",
    "axes[2].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inp = torch.tensor(coord_nor, dtype=torch.float32, requires_grad=True)\n",
    "u = Net_u(X_inp)*(func_u(X_inp).view(-1,1))\n",
    "du_x = auto_grad(u, X_inp, 1)[:,0].view(-1,1)\n",
    "du_y = auto_grad(u, X_inp, 1)[:,1].view(-1,1)\n",
    "v = Net_v(X_inp)*(func_v(X_inp).view(-1,1))\n",
    "dv_x = auto_grad(v, X_inp, 1)[:,0].view(-1,1)\n",
    "dv_y = auto_grad(v, X_inp, 1)[:,1].view(-1,1)\n",
    "w = Net_w(X_inp)*(func_w(X_inp).view(-1,1))\n",
    "dw_x = auto_grad(w, X_inp, 1)[:,0].view(-1,1)\n",
    "dw_y = auto_grad(w, X_inp, 1)[:,1].view(-1,1)\n",
    "dw_xx = auto_grad(dw_x, X_inp, 1)[:,0].view(-1,1)\n",
    "dw_yy = auto_grad(dw_y, X_inp, 1)[:,1].view(-1,1)\n",
    "dw_xy = auto_grad(dw_x, X_inp, 1)[:,1].view(-1,1)\n",
    "\n",
    "w = w*h\n",
    "dw_x, dw_y, du_y, dv_x = dw_x*h/a, dw_y*h/b, du_y*a/b, dv_x*b/a\n",
    "dw_xx, dw_yy, dw_xy = dw_xx*h/a**2, dw_yy*h/b**2, dw_xy*h/a/b\n",
    "\n",
    "eps_xx = du_x + 0.5*dw_x**2\n",
    "eps_yy = dv_y + 0.5*dw_y**2\n",
    "eps_xy = 0.5*(du_y + dv_x) + 0.5*dw_y*dw_x   \n",
    "\n",
    "k_xx = -dw_xx\n",
    "k_yy = -dw_yy\n",
    "k_xy = -dw_xy\n",
    "\n",
    "N_xx = A[0,0]*eps_xx + A[0,1]*eps_yy + A[0,2]*2*eps_xy  + B[0,0]*k_xx + B[0,1]*k_yy + B[0,2]*2*k_xy \n",
    "N_yy = A[1,0]*eps_xx + A[1,1]*eps_yy + A[1,2]*2*eps_xy  + B[1,0]*k_xx + B[1,1]*k_yy + B[1,2]*2*k_xy \n",
    "N_xy = A[2,0]*eps_xx + A[2,1]*eps_yy + A[2,2]*2*eps_xy  + B[2,0]*k_xx + B[2,1]*k_yy + B[2,2]*2*k_xy \n",
    "\n",
    "M_xx = B[0,0]*eps_xx + B[0,1]*eps_yy + B[0,2]*2*eps_xy  + D[0,0]*k_xx + D[0,1]*k_yy + D[0,2]*2*k_xy\n",
    "M_yy = B[1,0]*eps_xx + B[1,1]*eps_yy + B[1,2]*2*eps_xy  + D[1,0]*k_xx + D[1,1]*k_yy + D[1,2]*2*k_xy\n",
    "M_xy = B[2,0]*eps_xx + B[2,1]*eps_yy + B[2,2]*2*eps_xy  + D[2,0]*k_xx + D[2,1]*k_yy + D[2,2]*2*k_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3657b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN_sigmaxx = Q_bar[1][0,0]*eps_xx + Q_bar[1][0,1]*eps_yy + Q_bar[1][0,2]*2*eps_xy + 0.5* ( Q_bar[1][0,0]*k_xx +  Q_bar[1][0,1]*k_yy +  Q_bar[1][0,2]*2*k_xy )\n",
    "PINN_sigmayy = Q_bar[1][1,0]*eps_xx + Q_bar[1][1,1]*eps_yy + Q_bar[1][1,2]*2*eps_xy + 0.5* ( Q_bar[1][1,0]*k_xx +  Q_bar[1][1,1]*k_yy +  Q_bar[1][1,2]*2*k_xy )\n",
    "PINN_sigmaxy = Q_bar[1][2,0]*eps_xx + Q_bar[1][2,1]*eps_yy + Q_bar[1][2,2]*2*eps_xy + 0.5* ( Q_bar[1][2,0]*k_xx +  Q_bar[1][2,1]*k_yy +  Q_bar[1][2,2]*2*k_xy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN_sigmaxx = PINN_sigmaxx.detach().numpy()*(h)**2/q0/(2*a)**2\n",
    "PINN_sigmayy = PINN_sigmayy.detach().numpy()*(h)**2/q0/(2*a)**2\n",
    "PINN_sigmaxy = PINN_sigmaxy.detach().numpy()*(h)**2/q0/(2*a)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68458c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmaxx - sigmaxx)**2)  \n",
    "denominator = np.sum((sigmaxx - np.mean(sigmaxx))**2) \n",
    "sigmaxx_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmaxx):\", sigmaxx_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmayy - sigmayy)**2)  \n",
    "denominator = np.sum((sigmayy - np.mean(sigmayy))**2) \n",
    "sigmayy_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmayy):\", sigmayy_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmaxy - sigmaxy)**2)  \n",
    "denominator = np.sum((sigmaxy - np.mean(sigmaxy))**2) \n",
    "sigmaxy_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmaxy):\", sigmaxy_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "xticks = [-1, -0.5, 0, 0.5, 1] \n",
    "xlabels = ['-a', '-a/2', '0', 'a/2', 'a']\n",
    "yticks = [-1, -0.5, 0, 0.5, 1]\n",
    "ylabels = ['-b', '-b/2', '0', 'b/2', 'b'] \n",
    "surf1 = axes[0].scatter(X, Y, c=PINN_sigmaxx, cmap=cm.jet)\n",
    "cb1 = fig.colorbar(surf1, ax=axes[0], orientation='vertical', shrink=0.8)\n",
    "cb1.ax.tick_params(labelsize=16)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[0].set_ylabel('Y Position (mm)', fontsize=18)\n",
    "axes[0].set_title(f'$\\overline{{\\sigma}}_{{xx}}$ Distribution ($R^2$: {sigmaxx_r2})', fontsize=18)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[0].set_xlim([X.min(), X.max()])\n",
    "axes[0].set_ylim([Y.max(), Y.min()])\n",
    "axes[0].set_xticks(xticks)\n",
    "axes[0].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf2 = axes[1].scatter(X, Y, c=PINN_sigmayy, vmin=0, cmap=cm.jet)\n",
    "cb2 = fig.colorbar(surf2, ax=axes[1], orientation='vertical', shrink=0.8)\n",
    "cb2.ax.tick_params(labelsize=16)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[1].set_title(f'$\\overline{{\\sigma}}_{{yy}}$ Distribution ($R^2$: {sigmayy_r2})', fontsize=18)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[1].set_xlim([X.min(), X.max()])\n",
    "axes[1].set_ylim([Y.max(), Y.min()])\n",
    "axes[1].set_xticks(xticks)\n",
    "axes[1].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[1].set_yticks(yticks)\n",
    "axes[1].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf3 = axes[2].scatter(X, Y, c=PINN_sigmaxy, cmap=cm.jet)\n",
    "cb3 = fig.colorbar(surf3, ax=axes[2], orientation='vertical', shrink=0.8)\n",
    "cb3.ax.tick_params(labelsize=16)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[2].set_title(f'$\\overline{{\\sigma}}_{{xy}}$ Distribution ($R^2$: {sigmaxy_r2})', fontsize=18)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[2].set_xlim([X.min(), X.max()])\n",
    "axes[2].set_ylim([Y.max(), Y.min()])\n",
    "axes[2].set_xticks(xticks)\n",
    "axes[2].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[2].set_yticks(yticks)\n",
    "axes[2].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[2].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
