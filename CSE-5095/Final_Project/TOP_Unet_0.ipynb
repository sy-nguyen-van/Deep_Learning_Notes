{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopologyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_folder, output_folder):\n",
    "        self.input_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.mat')])\n",
    "        self.output_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.mat')])\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = output_folder\n",
    "        assert len(self.input_files) == len(self.output_files), \"Input/output mismatch\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = loadmat(os.path.join(self.input_folder, self.input_files[idx]))['X']  # H x W x 3\n",
    "        Y = loadmat(os.path.join(self.output_folder, self.output_files[idx]))['Y']  # H x W\n",
    "\n",
    "        X = torch.tensor(X.transpose(2, 0, 1), dtype=torch.float32)   # 3 x H x W\n",
    "        Y = torch.tensor(Y[np.newaxis, :, :], dtype=torch.float32)    # 1 x H x W\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.downs = nn.ModuleList()\n",
    "#         self.ups = nn.ModuleList()\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#         # Down part\n",
    "#         for feature in features:\n",
    "#             self.downs.append(self._block(in_channels, feature))\n",
    "#             in_channels = feature\n",
    "\n",
    "#         # Up part\n",
    "#         for feature in reversed(features):\n",
    "#             self.ups.append(\n",
    "#                 nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "#             )\n",
    "#             self.ups.append(self._block(feature * 2, feature))\n",
    "\n",
    "#         self.bottleneck = self._block(features[-1], features[-1] * 2)\n",
    "#         self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "#     def _block(self, in_channels, out_channels):\n",
    "#         return nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         skip_connections = []\n",
    "\n",
    "#         for down in self.downs:\n",
    "#             x = down(x)\n",
    "#             skip_connections.append(x)\n",
    "#             x = self.pool(x)\n",
    "\n",
    "#         x = self.bottleneck(x)\n",
    "#         skip_connections = skip_connections[::-1]\n",
    "\n",
    "#         for idx in range(0, len(self.ups), 2):\n",
    "#             x = self.ups[idx](x)\n",
    "#             skip_connection = skip_connections[idx // 2]\n",
    "#             if x.shape != skip_connection.shape:\n",
    "#                 x = F.interpolate(x, size=skip_connection.shape[2:])\n",
    "#             x = torch.cat((skip_connection, x), dim=1)\n",
    "#             x = self.ups[idx + 1](x)\n",
    "\n",
    "#         return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paths\n",
    "# train_input = 'data/train/input/'\n",
    "# train_output = 'data/train/output/'\n",
    "\n",
    "# # Dataset & Dataloader\n",
    "# dataset = TopologyDataset(train_input, train_output)\n",
    "# loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# # Device and model\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "# # Optimizer and loss\n",
    "# optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.MSELoss()  # or nn.L1Loss(), nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- Sinusoidal timestep embedding (standard in diffusion models) ----\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(\n",
    "            torch.arange(half_dim, device=device) * (-torch.log(torch.tensor(10000.0)) / (half_dim - 1))\n",
    "        )\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "# ---- Modified UNet for Diffusion ----\n",
    "class DiffusionUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, time_emb_dim=256, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Down blocks\n",
    "        for feature in features:\n",
    "            self.downs.append(self._block(in_channels, feature, time_emb_dim))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._block(features[-1], features[-1]*2, time_emb_dim)\n",
    "\n",
    "        # Up blocks\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(self._block(feature*2, feature, time_emb_dim))\n",
    "\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def _block(self, in_channels, out_channels, time_emb_dim):\n",
    "        return nn.ModuleDict({\n",
    "            \"conv1\": nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            \"bn1\": nn.BatchNorm2d(out_channels),\n",
    "            \"conv2\": nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            \"bn2\": nn.BatchNorm2d(out_channels),\n",
    "            \"time_emb\": nn.Linear(time_emb_dim, out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        skip_connections = []\n",
    "\n",
    "        # Downsampling\n",
    "        for down in self.downs:\n",
    "            x = self._forward_block(down, x, t_emb)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self._forward_block(self.bottleneck, x, t_emb)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Upsampling\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip = skip_connections[idx // 2]\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self._forward_block(self.ups[idx + 1], x, t_emb)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "    def _forward_block(self, block, x, t_emb):\n",
    "        h = F.relu(block[\"bn1\"](block[\"conv1\"](x)))\n",
    "        time_out = block[\"time_emb\"](t_emb)\n",
    "        # Broadcast to spatial dims\n",
    "        h = h + time_out[..., None, None]\n",
    "        h = F.relu(block[\"bn2\"](block[\"conv2\"](h)))\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  56%|█████████████████████████████████▌                          | 28/50 [00:11<00:08,  2.49it/s, loss=1.02]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- import your dataset ---\n",
    "# ====================================\n",
    "train_input = 'data/train/input/'\n",
    "train_output = 'data/train/output/'\n",
    "\n",
    "# Dataset & Dataloader\n",
    "dataset = TopologyDataset(train_input, train_output)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Device and model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DiffusionUNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ====================================\n",
    "# Diffusion hyperparameters\n",
    "timesteps = 1000\n",
    "betas = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# Helper: sample random timesteps for each batch\n",
    "def sample_timesteps(batch_size):\n",
    "    return torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "# ====================================\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for X, Y in pbar:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Add noise to the ground truth output\n",
    "        t = sample_timesteps(X.size(0))\n",
    "        noise = torch.randn_like(Y)\n",
    "        alpha_t = sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        alpha_bar_t = sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        Y_noisy = alpha_t * Y + alpha_bar_t * noise\n",
    "\n",
    "        # Predict noise with the model\n",
    "        noise_pred = model(torch.cat([X], dim=1), t)\n",
    "\n",
    "        # Loss between predicted and true noise\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "print(\"✅ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for X, Y in tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unet_topopt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Paths\n",
    "val_input = 'data/val/input/'\n",
    "val_output = 'data/val/output/'\n",
    "\n",
    "# Dataset & Dataloader\n",
    "dataset_val = TopologyDataset(val_input, val_output)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, Y_true = dataset_val[-1]\n",
    "    pred = model(X.unsqueeze(0).to(device))\n",
    "    pred = pred.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import scipy.io\n",
    "\n",
    "# ======================\n",
    "# Load mesh\n",
    "# ======================\n",
    "data = scipy.io.loadmat('Lbracket2d.mat')\n",
    "V = data['V']       # nverts x 2\n",
    "F = data['F'] - 1   # nelems x nodes, convert 1-based -> 0-based\n",
    "\n",
    "# ======================\n",
    "# Prepare predicted field\n",
    "# ======================\n",
    "# pred: should be nelems x 1 or flattened\n",
    "# if pred.shape != (n_elems,), flatten\n",
    "pred_flat = pred.flatten()\n",
    "\n",
    "# Normalize prediction to [0,1] for colormap\n",
    "pred_norm = (pred_flat - np.min(pred_flat)) / (np.max(pred_flat) - np.min(pred_flat) + 1e-12)\n",
    "\n",
    "# Colormap\n",
    "cmap = plt.cm.jet\n",
    "colors = cmap(pred_norm)\n",
    "\n",
    "# ======================\n",
    "# Create faces list\n",
    "# ======================\n",
    "faces = [V[face, :] for face in F]\n",
    "\n",
    "# ======================\n",
    "# Plot\n",
    "# ======================\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "mesh = PolyCollection(faces, facecolors=colors, edgecolors='k')  # show mesh edges\n",
    "ax.add_collection(mesh)\n",
    "\n",
    "# Formatting\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = data['V']       # nverts x 2\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data['F'] - 1   # nelems x nodes, convert 1-based -> 0-based\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
