{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopologyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_folder, output_folder):\n",
    "        self.input_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.mat')])\n",
    "        self.output_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.mat')])\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = output_folder\n",
    "        assert len(self.input_files) == len(self.output_files), \"Input/output mismatch\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = loadmat(os.path.join(self.input_folder, self.input_files[idx]))['X']  # H x W x 3\n",
    "        Y = loadmat(os.path.join(self.output_folder, self.output_files[idx]))['Y']  # H x W\n",
    "\n",
    "        X = torch.tensor(X.transpose(2, 0, 1), dtype=torch.float32)   # 3 x H x W\n",
    "        Y = torch.tensor(Y[np.newaxis, :, :], dtype=torch.float32)    # 1 x H x W\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Down part\n",
    "        for feature in features:\n",
    "            self.downs.append(self._block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(self._block(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = self._block(features[-1], features[-1] * 2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:])\n",
    "            x = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx + 1](x)\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_input = 'data/train/input/'\n",
    "train_output = 'data/train/output/'\n",
    "\n",
    "# Dataset & Dataloader\n",
    "dataset = TopologyDataset(train_input, train_output)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Device and model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()  # or nn.L1Loss(), nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|███████████████████████████████████████████████████████████████████████| 50/50 [00:21<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.028349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|███████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Loss: 0.006374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|███████████████████████████████████████████████████████████████████████| 50/50 [00:16<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] - Loss: 0.005331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:  44%|███████████████████████████████▏                                       | 22/50 [00:06<00:09,  3.11it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for X, Y in tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unet_topopt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Paths\n",
    "val_input = 'data/val/input/'\n",
    "val_output = 'data/val/output/'\n",
    "\n",
    "# Dataset & Dataloader\n",
    "dataset_val = TopologyDataset(val_input, val_output)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, Y_true = dataset_val[-1]\n",
    "    pred = model(X.unsqueeze(0).to(device))\n",
    "    pred = pred.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import scipy.io\n",
    "\n",
    "# ======================\n",
    "# Load mesh\n",
    "# ======================\n",
    "data = scipy.io.loadmat('Lbracket2d.mat')\n",
    "V = data['V']       # nverts x 2\n",
    "F = data['F'] - 1   # nelems x nodes, convert 1-based -> 0-based\n",
    "\n",
    "# ======================\n",
    "# Prepare predicted field\n",
    "# ======================\n",
    "# pred: should be nelems x 1 or flattened\n",
    "# if pred.shape != (n_elems,), flatten\n",
    "pred_flat = pred.flatten()\n",
    "\n",
    "# Normalize prediction to [0,1] for colormap\n",
    "pred_norm = (pred_flat - np.min(pred_flat)) / (np.max(pred_flat) - np.min(pred_flat) + 1e-12)\n",
    "\n",
    "# Colormap\n",
    "cmap = plt.cm.jet\n",
    "colors = cmap(pred_norm)\n",
    "\n",
    "# ======================\n",
    "# Create faces list\n",
    "# ======================\n",
    "faces = [V[face, :] for face in F]\n",
    "\n",
    "# ======================\n",
    "# Plot\n",
    "# ======================\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "mesh = PolyCollection(faces, facecolors=colors, edgecolors='k')  # show mesh edges\n",
    "ax.add_collection(mesh)\n",
    "\n",
    "# Formatting\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = data['V']       # nverts x 2\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data['F'] - 1   # nelems x nodes, convert 1-based -> 0-based\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
